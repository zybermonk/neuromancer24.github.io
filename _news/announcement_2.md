---
layout: post
title: The simulation hypothesis
date: 2021-03-25 16:11:00-0400
inline: false
---

This is an idea that I am currently fascinated about. I will be working on this for a good amount of time, so feel free to reach out to join in on this research. All backgrounds welcome :)

***
# Introduction

End is near, is it? We have been hearing this over the past couple of decades. Is it just an irrational fideism or maybe the prophecies have an error of -10+ , -100+ and so on. Schmidhuber try to
extend the naive analysis of past computer science breakthroughs in the intro-duction, which predicts that computer history will converge in an Omega point or historic singularity X
around 2040. Could it be that such lists just reflect the human way of allocating memory space to past events Maybe there is a general rule for both the individual memory of single humans and
the collective memory of entire societies and their history books. He basically tries to say if history repeats itself, which is the first research which I try to answer through my project.

1) [Will History Converge?](https://people.idsia.ch/~juergen/history.html) Is it a co-incidence or if there is a pattern repeating itself? This research question will be answered based on the research question 2.

One of the breakthroughs that can cause this next big revolution is the creation of a super Intelligence, or more specifically, Artificial General Intelligence. According to the above convergence
hypothesis, we are due to see this AGI in the next few decades. This idea gives rise to my second research question, that is,

2) What is the possibility of such an AGI to come into existence, if Yes, what is probability of an intelligence explosion?

[ There are two possible types of intelligence speedup: one due to faster operation of an intelligent system (clock speed increase or the hardware) and one due to an improvement in the type of mechanisms that
implement the thought processes (‘‘depth of thought’’ increase or the software). Obviously, both could occur at once (and there may be significant synergies), but the latter is ostensibly more difficult to achieve, and
may be subject to fundamental limits that we do not understand. Speeding up the hardware, on the other hand, is something that has been going on for a long time and is more mundane and reliable. Notice that both
routes lead to greater ‘‘intelligence,’’ because even a human level of thinking and creativity would be more effective if it were happening a thousand times faster than it does now. It seems possible that the general
class of AGI systems can be architected to take better advantage of improved hardware than would be the case with intelligent systems very narrowly imitative of the human brain. But even if this is not the case,
brute hardware speedup can still yield dramatic intelligent improvement.] This section of text from [Richard Loosemore](https://lists.extropy.org/pipermail/extropy-chat/2011-January/063255.html), suggests that the explosion can be measured and we can clearly discard limiting factors such
as investment ability, software complexity and hardware advancement.

**Hypothesis :** Once an AI system with roughly human-level general intelligence is created, an ‘‘intelligence explosion’’ involving the relatively rapid creation of increasingly more
generally intelligent AI systems will very likely ensue, resulting in the rapid emergence of dramatically superhuman intelligences.

**Null Hypothesis :** No creation of that SEED AGI to begin with.

# Papers in the field and Data Sources

1. [The Main Book](https://uol.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_askewsholts_vlebooks_9783642325601&context=PC&vid=353UOL_INST:353UOL_VU1&lang=en&search_scope=MyInst_and_CI&adaptor=Primo%20Central&tab=TAB1&query=any,contains,singularity%20hypothesis&sortby=rank) – UL Glucksman Library

2. [Research Question 1](https://link.springer.com/chapter/10.1007/978-3-642-32560-1_4)

3. [Research Question 2](https://lists.extropy.org/pipermail/extropy-chat/2011-January/063255.html)

4. [Forecasting model data](https://otexts.com/fpp2/forecasting-regression.html) and [Human level AGI forecast](https://commons.wikimedia.org/wiki/File:Estimations_of_Human_Brain_Emulation_Required_Performance.svg)

**Relevant research:**

> Baum, S. D., Goertzel, B., & Goertzel, T. G. (2011). How long until
human-level AI? results from an expert assessment. Technological
Forecasting and Social Change, 78(1), 185–195.

> Chalmers, D. (2010). The singularity: A philosophical analysis. Journal of Consciousness Studies, 17, 7–65.

> Goertzel, B. (2010). Toward a formal characterization of real-world general intelligence. Proceedings of AGI-10, Lugano.

> Hutter, M. (2005). Universal AI. Berlin: Springer.

> Sandberg, A. (2011, January 19). Limiting factors of intelligence explosion speeds. Extropy email

**Data Sources:**

[Private investment](https://fred.stlouisfed.org/series/Y006RC1Q027SBEA)

[Global GDP share on R&D](https://ourworldindata.org/grapher/research-and-development-expenditure-of-gdp?tab=chart&country=~OWID_WRL)

[Super-Computer Power](https://ourworldindata.org/grapher/supercomputer-power-flops?time=earliest..2020)

[Hardware Data](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-09-03)

[Transistors per Chip](https://ourworldindata.org/technological-progress)
